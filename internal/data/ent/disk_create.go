// Code generated by entc, DO NOT EDIT.

package ent

import (
	"context"
	"errors"
	"fmt"
	"time"

	"entgo.io/ent/dialect/sql/sqlgraph"
	"entgo.io/ent/schema/field"
	"github.com/menta2l/go-hwc/internal/data/ent/disk"
	"github.com/menta2l/go-hwc/internal/data/ent/host"
)

// DiskCreate is the builder for creating a Disk entity.
type DiskCreate struct {
	config
	mutation *DiskMutation
	hooks    []Hook
}

// SetDevice sets the "device" field.
func (dc *DiskCreate) SetDevice(s string) *DiskCreate {
	dc.mutation.SetDevice(s)
	return dc
}

// SetMountpoint sets the "Mountpoint" field.
func (dc *DiskCreate) SetMountpoint(s string) *DiskCreate {
	dc.mutation.SetMountpoint(s)
	return dc
}

// SetFstype sets the "Fstype" field.
func (dc *DiskCreate) SetFstype(s string) *DiskCreate {
	dc.mutation.SetFstype(s)
	return dc
}

// SetOpts sets the "opts" field.
func (dc *DiskCreate) SetOpts(s []string) *DiskCreate {
	dc.mutation.SetOpts(s)
	return dc
}

// SetCreatedAt sets the "created_at" field.
func (dc *DiskCreate) SetCreatedAt(t time.Time) *DiskCreate {
	dc.mutation.SetCreatedAt(t)
	return dc
}

// SetNillableCreatedAt sets the "created_at" field if the given value is not nil.
func (dc *DiskCreate) SetNillableCreatedAt(t *time.Time) *DiskCreate {
	if t != nil {
		dc.SetCreatedAt(*t)
	}
	return dc
}

// SetUpdatedAt sets the "updated_at" field.
func (dc *DiskCreate) SetUpdatedAt(t time.Time) *DiskCreate {
	dc.mutation.SetUpdatedAt(t)
	return dc
}

// SetNillableUpdatedAt sets the "updated_at" field if the given value is not nil.
func (dc *DiskCreate) SetNillableUpdatedAt(t *time.Time) *DiskCreate {
	if t != nil {
		dc.SetUpdatedAt(*t)
	}
	return dc
}

// SetHostIDID sets the "host_id" edge to the Host entity by ID.
func (dc *DiskCreate) SetHostIDID(id string) *DiskCreate {
	dc.mutation.SetHostIDID(id)
	return dc
}

// SetHostID sets the "host_id" edge to the Host entity.
func (dc *DiskCreate) SetHostID(h *Host) *DiskCreate {
	return dc.SetHostIDID(h.ID)
}

// Mutation returns the DiskMutation object of the builder.
func (dc *DiskCreate) Mutation() *DiskMutation {
	return dc.mutation
}

// Save creates the Disk in the database.
func (dc *DiskCreate) Save(ctx context.Context) (*Disk, error) {
	var (
		err  error
		node *Disk
	)
	dc.defaults()
	if len(dc.hooks) == 0 {
		if err = dc.check(); err != nil {
			return nil, err
		}
		node, err = dc.sqlSave(ctx)
	} else {
		var mut Mutator = MutateFunc(func(ctx context.Context, m Mutation) (Value, error) {
			mutation, ok := m.(*DiskMutation)
			if !ok {
				return nil, fmt.Errorf("unexpected mutation type %T", m)
			}
			if err = dc.check(); err != nil {
				return nil, err
			}
			dc.mutation = mutation
			if node, err = dc.sqlSave(ctx); err != nil {
				return nil, err
			}
			mutation.id = &node.ID
			mutation.done = true
			return node, err
		})
		for i := len(dc.hooks) - 1; i >= 0; i-- {
			if dc.hooks[i] == nil {
				return nil, fmt.Errorf("ent: uninitialized hook (forgotten import ent/runtime?)")
			}
			mut = dc.hooks[i](mut)
		}
		if _, err := mut.Mutate(ctx, dc.mutation); err != nil {
			return nil, err
		}
	}
	return node, err
}

// SaveX calls Save and panics if Save returns an error.
func (dc *DiskCreate) SaveX(ctx context.Context) *Disk {
	v, err := dc.Save(ctx)
	if err != nil {
		panic(err)
	}
	return v
}

// Exec executes the query.
func (dc *DiskCreate) Exec(ctx context.Context) error {
	_, err := dc.Save(ctx)
	return err
}

// ExecX is like Exec, but panics if an error occurs.
func (dc *DiskCreate) ExecX(ctx context.Context) {
	if err := dc.Exec(ctx); err != nil {
		panic(err)
	}
}

// defaults sets the default values of the builder before save.
func (dc *DiskCreate) defaults() {
	if _, ok := dc.mutation.CreatedAt(); !ok {
		v := disk.DefaultCreatedAt()
		dc.mutation.SetCreatedAt(v)
	}
	if _, ok := dc.mutation.UpdatedAt(); !ok {
		v := disk.DefaultUpdatedAt()
		dc.mutation.SetUpdatedAt(v)
	}
}

// check runs all checks and user-defined validators on the builder.
func (dc *DiskCreate) check() error {
	if _, ok := dc.mutation.Device(); !ok {
		return &ValidationError{Name: "device", err: errors.New(`ent: missing required field "Disk.device"`)}
	}
	if _, ok := dc.mutation.Mountpoint(); !ok {
		return &ValidationError{Name: "Mountpoint", err: errors.New(`ent: missing required field "Disk.Mountpoint"`)}
	}
	if _, ok := dc.mutation.Fstype(); !ok {
		return &ValidationError{Name: "Fstype", err: errors.New(`ent: missing required field "Disk.Fstype"`)}
	}
	if _, ok := dc.mutation.CreatedAt(); !ok {
		return &ValidationError{Name: "created_at", err: errors.New(`ent: missing required field "Disk.created_at"`)}
	}
	if _, ok := dc.mutation.UpdatedAt(); !ok {
		return &ValidationError{Name: "updated_at", err: errors.New(`ent: missing required field "Disk.updated_at"`)}
	}
	if _, ok := dc.mutation.HostIDID(); !ok {
		return &ValidationError{Name: "host_id", err: errors.New(`ent: missing required edge "Disk.host_id"`)}
	}
	return nil
}

func (dc *DiskCreate) sqlSave(ctx context.Context) (*Disk, error) {
	_node, _spec := dc.createSpec()
	if err := sqlgraph.CreateNode(ctx, dc.driver, _spec); err != nil {
		if sqlgraph.IsConstraintError(err) {
			err = &ConstraintError{err.Error(), err}
		}
		return nil, err
	}
	id := _spec.ID.Value.(int64)
	_node.ID = int(id)
	return _node, nil
}

func (dc *DiskCreate) createSpec() (*Disk, *sqlgraph.CreateSpec) {
	var (
		_node = &Disk{config: dc.config}
		_spec = &sqlgraph.CreateSpec{
			Table: disk.Table,
			ID: &sqlgraph.FieldSpec{
				Type:   field.TypeInt,
				Column: disk.FieldID,
			},
		}
	)
	if value, ok := dc.mutation.Device(); ok {
		_spec.Fields = append(_spec.Fields, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: disk.FieldDevice,
		})
		_node.Device = value
	}
	if value, ok := dc.mutation.Mountpoint(); ok {
		_spec.Fields = append(_spec.Fields, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: disk.FieldMountpoint,
		})
		_node.Mountpoint = value
	}
	if value, ok := dc.mutation.Fstype(); ok {
		_spec.Fields = append(_spec.Fields, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: disk.FieldFstype,
		})
		_node.Fstype = value
	}
	if value, ok := dc.mutation.Opts(); ok {
		_spec.Fields = append(_spec.Fields, &sqlgraph.FieldSpec{
			Type:   field.TypeJSON,
			Value:  value,
			Column: disk.FieldOpts,
		})
		_node.Opts = value
	}
	if value, ok := dc.mutation.CreatedAt(); ok {
		_spec.Fields = append(_spec.Fields, &sqlgraph.FieldSpec{
			Type:   field.TypeTime,
			Value:  value,
			Column: disk.FieldCreatedAt,
		})
		_node.CreatedAt = value
	}
	if value, ok := dc.mutation.UpdatedAt(); ok {
		_spec.Fields = append(_spec.Fields, &sqlgraph.FieldSpec{
			Type:   field.TypeTime,
			Value:  value,
			Column: disk.FieldUpdatedAt,
		})
		_node.UpdatedAt = value
	}
	if nodes := dc.mutation.HostIDIDs(); len(nodes) > 0 {
		edge := &sqlgraph.EdgeSpec{
			Rel:     sqlgraph.M2O,
			Inverse: true,
			Table:   disk.HostIDTable,
			Columns: []string{disk.HostIDColumn},
			Bidi:    false,
			Target: &sqlgraph.EdgeTarget{
				IDSpec: &sqlgraph.FieldSpec{
					Type:   field.TypeString,
					Column: host.FieldID,
				},
			},
		}
		for _, k := range nodes {
			edge.Target.Nodes = append(edge.Target.Nodes, k)
		}
		_node.host_disk = &nodes[0]
		_spec.Edges = append(_spec.Edges, edge)
	}
	return _node, _spec
}

// DiskCreateBulk is the builder for creating many Disk entities in bulk.
type DiskCreateBulk struct {
	config
	builders []*DiskCreate
}

// Save creates the Disk entities in the database.
func (dcb *DiskCreateBulk) Save(ctx context.Context) ([]*Disk, error) {
	specs := make([]*sqlgraph.CreateSpec, len(dcb.builders))
	nodes := make([]*Disk, len(dcb.builders))
	mutators := make([]Mutator, len(dcb.builders))
	for i := range dcb.builders {
		func(i int, root context.Context) {
			builder := dcb.builders[i]
			builder.defaults()
			var mut Mutator = MutateFunc(func(ctx context.Context, m Mutation) (Value, error) {
				mutation, ok := m.(*DiskMutation)
				if !ok {
					return nil, fmt.Errorf("unexpected mutation type %T", m)
				}
				if err := builder.check(); err != nil {
					return nil, err
				}
				builder.mutation = mutation
				nodes[i], specs[i] = builder.createSpec()
				var err error
				if i < len(mutators)-1 {
					_, err = mutators[i+1].Mutate(root, dcb.builders[i+1].mutation)
				} else {
					spec := &sqlgraph.BatchCreateSpec{Nodes: specs}
					// Invoke the actual operation on the latest mutation in the chain.
					if err = sqlgraph.BatchCreate(ctx, dcb.driver, spec); err != nil {
						if sqlgraph.IsConstraintError(err) {
							err = &ConstraintError{err.Error(), err}
						}
					}
				}
				if err != nil {
					return nil, err
				}
				mutation.id = &nodes[i].ID
				mutation.done = true
				if specs[i].ID.Value != nil {
					id := specs[i].ID.Value.(int64)
					nodes[i].ID = int(id)
				}
				return nodes[i], nil
			})
			for i := len(builder.hooks) - 1; i >= 0; i-- {
				mut = builder.hooks[i](mut)
			}
			mutators[i] = mut
		}(i, ctx)
	}
	if len(mutators) > 0 {
		if _, err := mutators[0].Mutate(ctx, dcb.builders[0].mutation); err != nil {
			return nil, err
		}
	}
	return nodes, nil
}

// SaveX is like Save, but panics if an error occurs.
func (dcb *DiskCreateBulk) SaveX(ctx context.Context) []*Disk {
	v, err := dcb.Save(ctx)
	if err != nil {
		panic(err)
	}
	return v
}

// Exec executes the query.
func (dcb *DiskCreateBulk) Exec(ctx context.Context) error {
	_, err := dcb.Save(ctx)
	return err
}

// ExecX is like Exec, but panics if an error occurs.
func (dcb *DiskCreateBulk) ExecX(ctx context.Context) {
	if err := dcb.Exec(ctx); err != nil {
		panic(err)
	}
}
